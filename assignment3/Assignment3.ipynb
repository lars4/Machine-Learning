{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Unsupervised Learning\n",
    "\n",
    "In this assignment you will:\n",
    "* Implement K-means clustering and use it for color-quantization of images\n",
    "* Train a MoG model by implementing the EM algorithm. Compare to K-means on the same test data. \n",
    "* Use PCA for image compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: K-Means Clustering\n",
    "\n",
    "## Setup\n",
    "\n",
    "First import the required packages and do some setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy import misc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from assignment3 import kmeans, kmeans_colors, em_mog, em_segmentation, getEigenImages\n",
    "\n",
    "# Set default parameters for plots\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'jet'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some test-data for you to test your implementation of the k-means and EM algorithm. Note that we generate gaussian blobs with non-isotropic covariance matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate samples of 4 different Gaussians\n",
    "rv1 = multivariate_normal.rvs([4.0, -3.], [[4.0, 1.5], [1.5, 1.1]], size=400)\n",
    "rv2 = multivariate_normal.rvs([4.0, 3.5], [[1.0, 2.3], [0.8, 2.75]], size=500)\n",
    "rv3 = multivariate_normal.rvs([-3.5, -4.0], [[0.5, 1.0], [0.3, 3.]], size=600)\n",
    "rv4 = multivariate_normal.rvs([-3., 3.], [[2.5, 0.1], [2.3, 1.5]], size=700)\n",
    "\n",
    "# Concatenate the samples and create corresponding labels\n",
    "X = np.concatenate([rv1, rv2, rv3, rv4], 0)\n",
    "y = np.array([0]*400+[1]*500+[2]*600+[3]*700)\n",
    "\n",
    "# Plot the test data\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.title(\"Test Blobs\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: K-Means Clustering [15 Points]\n",
    "\n",
    "You will now implement the standard k-means clustering algorithm and test it on the generated test data. \n",
    "\n",
    "**TODO**: Implement the k-means clustering algorithm in ***kmeans.py*** according to specs and test your implementation with the provided test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test your implementation\n",
    "centers, assign = kmeans(X, 4)\n",
    "plt.clf()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=assign)\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='r', marker='x')\n",
    "plt.title(\"Predicted clustering\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Questions about K-means [10 Points]\n",
    "\n",
    "* Does k-means always result in the same clustering? Why?\n",
    "\n",
    "***Your Answer:***\n",
    "\n",
    "* Would you expect K-means to work better in the case of data generated from isotropic Gaussian distributions? Why?\n",
    "\n",
    "***Your Answer:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Using k-means for image compression [10 Points]\n",
    "\n",
    "You will now use K-means to cluster pixel values of an image and use the cluster assignments as a way to quantize/compress the color-space of the image. Replace each pixel with the mean of the assigned cluster.\n",
    "You should use the implementation provided through sklearn in this exercise ([sklearn.cluster.KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)).\n",
    "\n",
    "Feel free to test the algorithm on your own images and with different numbers of clusters.\n",
    "\n",
    "**TODO**: Implement the color-quantization through k-means in ***kmeans_colors.py*** according to specs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load and show test image\n",
    "img = misc.imread('lena.png')\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original image\")\n",
    "plt.show()\n",
    "\n",
    "# Compute quantized image\n",
    "k = 4\n",
    "img_cl = kmeans_colors(img, k)\n",
    "\n",
    "# Show the quantized image\n",
    "plt.imshow(img_cl)\n",
    "plt.title(\"Quantized image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Expectation Maximization\n",
    "\n",
    "In the second part of the assignment you will implement the EM algorithm for Mixture of Gaussian (MoG) models. You will then use this model on the problem of image-segmentation.\n",
    "\n",
    "\n",
    "## Exercise 4: EM for MoG [25 Points]\n",
    "\n",
    "**TODO:** Implement the **EM** algorithm for Mixture of Gaussian models in **em_mog.py** according to specs. Test your implementation on the provided test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test your implementation\n",
    "phi, mu, sigma, w = em_mog(X, 4)\n",
    "plt.clf()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=np.argmax(w, 1))\n",
    "plt.scatter(mu[:, 0], mu[:, 1], c='r', marker='x')\n",
    "plt.title(\"Predicted clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 5: Questions about MoG [10 Points]\n",
    "\n",
    "* Does the MoG model perform better than K-means on the provided test data? Why?\n",
    "\n",
    "***Your Answer:***\n",
    "\n",
    "* What are advantages and disadvantages of MoG vs. K-means?\n",
    "\n",
    "***Your Answer:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: EigenFaces with PCA [5 Points]\n",
    "In this exercise you will implement an image compression method using PCA. \n",
    "Below are the steps that you need to do:\n",
    "* Stack all the images of faces in the design matrix \n",
    "* Perform SVD (Singular Value Decomposition) of the design matrix\n",
    "* Get the _right_ eigenvectors corresponding to the N largest eigenvalues\n",
    "* Project a test image onto the basis of eigenvectors from the previous step\n",
    "\n",
    "In order to reconstruct the compressed image you need to compute the linear combination of the projection coefficients and corresponding _right_ eigenvectors. For more details please visit: https://en.wikipedia.org/wiki/Principal_component_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset of faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('faces.mat')\n",
    "labels = np.squeeze(data['Labels'])\n",
    "data = data['Data']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1)\n",
    "num_train = X_train.shape[0]\n",
    "num_test = X_test.shape[0]\n",
    "\n",
    "# Zero centering data\n",
    "scaler = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=False)\n",
    "scaler.fit(data[labels==1])\n",
    "\n",
    "# Selecting only faces\n",
    "X_faces_train = scaler.transform(X_train[y_train==1])\n",
    "X_faces_test = scaler.transform(X_test[y_test==1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying some of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    plt.subplot(3, 3, i)\n",
    "    plt.imshow(np.reshape(X_faces_train[i-1,:], [24, 24], order='F'), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA to the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "U=None \n",
    "S=None \n",
    "Vh=None\n",
    "\n",
    "#######################################################################\n",
    "# TODO:                                                               #\n",
    "#      Perform the singular value decomposition (SVD) of the face     #\n",
    "#      data matrix and    #\n",
    "#      extract the eigenvectors                                       #\n",
    "#      Input: X_faces_train\n",
    "#      Output: U, S, and Vh matrices of the SVD\n",
    "#######################################################################\n",
    "\n",
    "pass\n",
    "\n",
    "#######################################################################\n",
    "#                         END OF YOUR CODE                            #\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some of the EigenFaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenface = np.reshape(Vh, [-1, 24, 24], order='F')\n",
    "\n",
    "N=9\n",
    "\n",
    "for i in range(1,N+1):\n",
    "    plt.subplot(int(np.sqrt(N)), int(np.sqrt(N)), i)\n",
    "    plt.imshow(eigenface[i-1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Compression using PCA [10 Points]\n",
    "\n",
    "Compress the test set images using eigenvectors computed in the previous exercise\n",
    "\n",
    "**TODO:** Implement the **Compression with PCA** in **getEigenImages.py** according to specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting some number of EigenFaces\n",
    "num_components = 200\n",
    "basis = Vh[:num_components,:].T\n",
    "\n",
    "eigen_coefficients, reconstruction = getEigenImages(X_faces_test, basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation on the provided test data. Display the reconstructed and original images side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_images = np.reshape(reconstruction,[-1, 24,24], order='F')\n",
    "test_images = np.reshape(X_faces_test,[-1, 24,24], order='F')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16.0, 3.0)\n",
    "\n",
    "num_faces = 9\n",
    "\n",
    "for i in range(1,num_faces+1):\n",
    "    plt.subplot(2, num_faces, i)\n",
    "    plt.imshow(test_images[i-1,:,:], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2, num_faces, num_faces + i)\n",
    "    plt.imshow(reconstructed_images[i-1,:,:], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Evaluating the Quality of the Compression [5 Points]\n",
    "\n",
    "Compress the images from the test set using different numbers of eigenvectors. Measure the quality of the reconstructions using MSE. Plot the dependency of MSE on the number of eigenvectors used for the reconstruction. Recall that the MSE between two images is defined as\n",
    "\n",
    "$$MSE(X,Y)= \\frac { 1 } { m n } \\sum _ { i = 0 } ^ { m - 1 } \\sum _ { j = 0 } ^ { n - 1 } [ X ( i , j ) - Y ( i , j ) ] ^ { 2 }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigen_vectors_list = range(24,577,24)\n",
    "mse_list = []\n",
    "\n",
    "for num_eigen_vectors in num_eigen_vectors_list:\n",
    "    basis = Vh[:num_eigen_vectors,:].T\n",
    "    \n",
    "    eigen_coefficients, reconstruction = getEigenImages(X_faces_test, basis)\n",
    "    \n",
    "    #######################################################################\n",
    "    # TODO:                                                               #\n",
    "    #      Compute MSE between reconstruction and original image          #                                  \n",
    "    #######################################################################\n",
    "    \n",
    "    pass\n",
    "    \n",
    "    #######################################################################\n",
    "    #                         END OF YOUR CODE                            #\n",
    "    #######################################################################\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(num_eigen_vectors_list, mse_list)\n",
    "\n",
    "ax.set(xlabel='Number of EigenFaces', ylabel='MSE',\n",
    "       title='Dependency of MSE on the Number of EigenFaces')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: EigenFace with PCA [10 Points]\n",
    "\n",
    "* In the lecture notes you were computing the eigenvectors of the data covariance matrix, while in assignment you computed them by directly performing SVD on the design matrix. What is the difference between the two approaches? Which approach is better? Justify your answer.\n",
    "\n",
    "***Your Answer:***\n",
    "\n",
    "\n",
    "* Discuss the quality of the reconstructions and advantages of using PCA for compression.\n",
    "\n",
    "***Your Answer:***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
